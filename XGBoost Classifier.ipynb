{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/84/4e2cae6247f397f83d8adc5c2a2a0c5d7d790a14a4c7400ff6574586f589/xgboost-0.90.tar.gz (676kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./anaconda3/lib/python3.6/site-packages (from xgboost) (1.17.1)\n",
      "Requirement already satisfied: scipy in ./anaconda3/lib/python3.6/site-packages (from xgboost) (1.3.2)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/snerur/Library/Caches/pip/wheels/e9/48/4d/de4187b5270dff71d3697c5a7857a1e2d9a0c63a28b3462eeb\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This example is from: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "#URL for the dataset is given below\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import pandas as pd #for reading in data\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768.0</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>768.0</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>117.0000</td>\n",
       "      <td>140.25000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768.0</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>768.0</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768.0</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>127.25000</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>768.0</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.30000</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>36.60000</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.24375</td>\n",
       "      <td>0.3725</td>\n",
       "      <td>0.62625</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>768.0</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>768.0</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        mean         std     min       25%       50%        75%  \\\n",
       "0  768.0    3.845052    3.369578   0.000   1.00000    3.0000    6.00000   \n",
       "1  768.0  120.894531   31.972618   0.000  99.00000  117.0000  140.25000   \n",
       "2  768.0   69.105469   19.355807   0.000  62.00000   72.0000   80.00000   \n",
       "3  768.0   20.536458   15.952218   0.000   0.00000   23.0000   32.00000   \n",
       "4  768.0   79.799479  115.244002   0.000   0.00000   30.5000  127.25000   \n",
       "5  768.0   31.992578    7.884160   0.000  27.30000   32.0000   36.60000   \n",
       "6  768.0    0.471876    0.331329   0.078   0.24375    0.3725    0.62625   \n",
       "7  768.0   33.240885   11.760232  21.000  24.00000   29.0000   41.00000   \n",
       "8  768.0    0.348958    0.476951   0.000   0.00000    0.0000    1.00000   \n",
       "\n",
       "      max  \n",
       "0   17.00  \n",
       "1  199.00  \n",
       "2  122.00  \n",
       "3   99.00  \n",
       "4  846.00  \n",
       "5   67.10  \n",
       "6    2.42  \n",
       "7   81.00  \n",
       "8    1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(url, header=None)\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#any missing values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the last column is the target\n",
    "features = data[data.columns[:-1]]\n",
    "target = data[data.columns[-1]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, \\\n",
    "                                                   random_state = 99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = XGBClassifier()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9087523277467412\n",
      "Test accuracy:  0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", classifier.score(x_train,y_train))\n",
    "print(\"Test accuracy: \", classifier.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,  35],\n",
       "       [ 21,  55]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "predicted = classifier.predict(x_test)\n",
    "confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       155\n",
      "           1       0.61      0.72      0.66        76\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.73      0.75      0.74       231\n",
      "weighted avg       0.77      0.76      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(classifier.feature_importances_)), classifier.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us try a Voting Classifier - a majority vote classifier that aggregates the predictions of\n",
    "#several weak classifiers\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "lr = LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n",
    "knn = KNeighborsClassifier()\n",
    "xg = xgb.XGBClassifier()\n",
    "svc = SVC(gamma = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC :  0.670995670995671\n",
      "LogisticRegression :  0.7748917748917749\n",
      "KNeighborsClassifier :  0.7532467532467533\n",
      "XGBClassifier :  0.7575757575757576\n",
      "VotingClassifier :  0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "voting_classifier = VotingClassifier(\n",
    "                        estimators = [('svc', svc),('lr', lr),('knn', knn),('xg', xg)],voting = 'hard')\n",
    "for classifier in (svc, lr, knn, xg, voting_classifier):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(classifier.__class__.__name__, \": \", accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :  0.7748917748917749\n",
      "KNeighborsClassifier :  0.7532467532467533\n",
      "XGBClassifier :  0.7575757575757576\n",
      "VotingClassifier :  0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "#with soft voting\n",
    "voting_classifier = VotingClassifier(\n",
    "                        estimators = [('lr', lr),('knn', knn),('xg', xg)],voting = 'soft')\n",
    "for classifier in (lr, knn, xg, voting_classifier):\n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    print(classifier.__class__.__name__, \": \", accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
